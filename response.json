❯ python -m example.simple_example
Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Gemini 2.5 Pro Preview doesn't have a free quota tier. For more information on this error, head to: https: //ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro-exp"
}
  quota_dimensions {
    key: "location"
    value: "global"
}
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro-exp"
}
  quota_dimensions {
    key: "location"
    value: "global"
}
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerMinute-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro-exp"
}
  quota_dimensions {
    key: "location"
    value: "global"
}
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerDay-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro-exp"
}
  quota_dimensions {
    key: "location"
    value: "global"
}
}, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}, retry_delay {
  seconds: 10
}
].
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/Users/d.shahbazyan/dev/LLM_Service/example/simple_example.py", line 71, in <module>
    asyncio.run(main())
  File "/Users/d.shahbazyan/.local/share/uv/python/cpython-3.12.3-macos-aarch64-none/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/.local/share/uv/python/cpython-3.12.3-macos-aarch64-none/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/.local/share/uv/python/cpython-3.12.3-macos-aarch64-none/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/example/simple_example.py", line 66, in main
    await gemini()
  File "/Users/d.shahbazyan/dev/LLM_Service/example/simple_example.py", line 48, in gemini
    result = await llm.ainvoke(message='Сколько будет 2 + 2?')
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/llm/service.py", line 83, in ainvoke
    result = await self.__ainvoke(chat_for_model=chat_for_model, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/llm/billing.py", line 26, in __call__
    result: AIMessage | PydanticSchema = await self.func(*args, **kwargs)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/llm/service.py", line 93, in __ainvoke
    return await self.client.ainvoke(chat_for_model, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 394, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 968, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 926, in agenerate
    raise exceptions[
0
]
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 1094, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py", line 1391, in _agenerate
    response: GenerateContentResponse = await _achat_with_retry(
                                        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py", line 243, in _achat_with_retry
    return await _achat_with_retry(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped
    return await copy(fn, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__
    do = await self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/.local/share/uv/python/cpython-3.12.3-macos-aarch64-none/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/.local/share/uv/python/cpython-3.12.3-macos-aarch64-none/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__
    result = await fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py", line 241, in _achat_with_retry
    raise e
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py", line 234, in _achat_with_retry
    return await generation_method(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/async_client.py", line 444, in generate_content
    response = await rpc(
               ^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary_async.py", line 231, in retry_wrapped_func
    return await retry_target(
           ^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary_async.py", line 163, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary_async.py", line 158, in retry_target
    return await target()
           ^^^^^^^^^^^^^^
  File "/Users/d.shahbazyan/dev/LLM_Service/venv/lib/python3.12/site-packages/google/api_core/grpc_helpers_async.py", line 88, in __await__
    raise exceptions.from_grpc_error(rpc_error) from rpc_error
google.api_core.exceptions.ResourceExhausted: 429 Gemini 2.5 Pro Preview doesn't have a free quota tier. For more information on this error, head to: https: //ai.google.dev/gemini-api/docs/rate-limits. [violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerDay-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro-exp"
}
  quota_dimensions {
    key: "location"
    value: "global"
}
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerMinute-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro-exp"
}
  quota_dimensions {
    key: "location"
    value: "global"
}
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro-exp"
}
  quota_dimensions {
    key: "location"
    value: "global"
}
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-pro-exp"
}
  quota_dimensions {
    key: "location"
    value: "global"
}
}, links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}, retry_delay {
  seconds: 7
}
]
